{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7900ff77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmadr\\Documents\\Projects\\datacamp\\17. limpando dados.ipynb Célula: 2\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmadr/Documents/Projects/datacamp/17.%20limpando%20dados.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmadr/Documents/Projects/datacamp/17.%20limpando%20dados.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lmadr/Documents/Projects/datacamp/17.%20limpando%20dados.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmissingno\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmsno\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmadr/Documents/Projects/datacamp/17.%20limpando%20dados.ipynb#Y103sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmadr/Documents/Projects/datacamp/17.%20limpando%20dados.ipynb#Y103sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfuzzywuzzy\u001b[39;00m \u001b[39mimport\u001b[39;00m fuzz, process\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5a87f",
   "metadata": {},
   "source": [
    "### Restrições de tipos de dados\n",
    "\n",
    "É possível que alguma feature possui dados com um data type não usual, o que pode causar problemas de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # verificar valores ausentes\n",
    "df.dtypes # mostra o tipo de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# números como string (exemplo: '57$')  -> e se o sifrão estiver no começo?\n",
    "df['price'].sum() # retorna concatenação das strings\n",
    "\n",
    "# converter:\n",
    "df['price'] = df['price'].str.strip('$') # retira o caractere do exemplo\n",
    "df['price'] = df['price'].astype('int') # converte\n",
    "\n",
    "# verificar:\n",
    "assert df['price'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69dcd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categórico como inteiro (exemplo: 0 para não, 1 para sim)\n",
    "df['maried'].describe() # vai retornar média, desvio padrão etc.\n",
    "    # era melhor dados estatísticos de frêquencia para categorias\n",
    "    \n",
    "# converter:\n",
    "df['maried'] = df['maried'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cbb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data como objeto:\n",
    "df.dtypes\n",
    "\n",
    "# converter:\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# assert:\n",
    "assert user_signups['subscription_date'].dtype == 'datetime64[ns]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5df0a9",
   "metadata": {},
   "source": [
    "### Restrições de intervalo\n",
    "\n",
    "Exemplo: \n",
    "- 6 estrelas em avaliação de 1 a 5;\n",
    "- Registro em data no futuro.\n",
    "\n",
    "Soluções:\n",
    "- dropar o registro (não recomendado se temos muitos registros com o problema)\n",
    "- setar mínimos e máximos e substituir\n",
    "- tratar o dado como faltante e imputá-lo ()\n",
    "- substituir por um valor fixo (como a média, mediana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab1d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrando datas futuras\n",
    "import datetime as dt\n",
    "df[df['date']>dt.date.today()]\n",
    "\n",
    "# dropando datas futuras\n",
    "today_date = dt.date.today()\n",
    "# Drop values using filtering\n",
    "df = df[df['subscription_date'] < today_date]\n",
    "# Drop values using .drop()\n",
    "df.drop(df[df['subscription_date'] > today_date].index, inplace = True)\n",
    "\n",
    "# substituindo\n",
    "# using filtering\n",
    "df.loc[df['subscription_date'] > today_date, 'subscription_date'] = today_date\n",
    "# Assert is true\n",
    "assert df.subscription_date.max().date() <= today_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando: filtrando e atribuindo\n",
    "df = df[df['rating']<=5]\n",
    "\n",
    "# dropando: método drop\n",
    "df.drop(df[df['rating']>5].index, inplace = True) # inplace = true: método .drop modifica o objeto; se = False ele deve ser atribuido a outra variável.\n",
    "\n",
    "# verificação:\n",
    "assert df['rating'].max() <=5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7940ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituindo pelo limite:\n",
    "df.loc[df['rating'] > 5, 'rating'] = 5 # com esse segundo argumento seleciona so a coluna 'rating'\n",
    "\n",
    "# assert igual a anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d73e4",
   "metadata": {},
   "source": [
    "### Registros duplicados\n",
    "\n",
    "- Registros inteiros duplicados -> drope um deles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificando\n",
    "duplicates = df.duplicated() # booleano True para linhas duplicadas; False em todas as primeiras ocorrências\n",
    "df[df.duplicated()] # retorna todas as linhas duplicadas\n",
    "\n",
    "# argumentos do método .duplicated()\n",
    "df2 = df[df.duplicated(subset = ['column1', 'column2'])]    # subset: especificamos quais colunas checar por duplicatas; recebe lista de nomes de features/colunas \n",
    "df2 = df[df.duplicated(keep = 'first')]    #keep: admite as strings 'first' (default), 'last' e False; mantém (retorna False para) a ocorrência especificada\n",
    "\n",
    "# checando após modificação:\n",
    "df[df.duplicated()].sorf_values(by = 'column1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c87ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando duplicatas completos (registro inteiro é duplicado)\n",
    "\n",
    "# método .drop_duplicates(): obs.:os argumentos são: subset, keep e inplace (iguais aos do .duplicated() e .drop())\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ca9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando duplicatas com divergências numéricas:\n",
    "\n",
    "# Output duplicate values\n",
    "column_names = ['first_name','last_name','address']\n",
    "duplicates = df.duplicated(subset = column_names, keep = False)\n",
    "df[duplicates].sort_values(by = 'first_name')\n",
    "\n",
    "# decisão por estatística:encadeado método .groupby() e .agg()\n",
    "# Group by column names and produce statistical summaries\n",
    "column_names = ['first_name','last_name','address'] # colunas a agrupar (cujos valores serão duplicados)\n",
    "summaries = {'height': 'max', 'weight': 'mean'} # colunas divergentes e o tipo de agregação (máximo e média)\n",
    "df = df.groupby(by = column_names).agg(summaries).reset_index() # agrupa pela lista column_names; agrega pelo dict summaries\n",
    "    # reset_index para criar novo índice após a agregação\n",
    "# Make sure aggregation is done\n",
    "duplicates = df.duplicated(subset = column_names, keep = False)\n",
    "df[duplicates].sort_values(by = 'first_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb124c",
   "metadata": {},
   "source": [
    "### Membership constraints / restrições de associação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c437910",
   "metadata": {},
   "source": [
    "#### Dados categóricos\n",
    "\n",
    "- Normalmente representados por um conjunto finito de inteiros e não admite outros valores;\n",
    "- erros aqui costumam vir de campos de texto livre (caixa de texto) ou campos suspensos (campo com lista selecionável), ou ainda erro de parsing dos dados.\n",
    "\n",
    "Temos 3 tipos de solução:\n",
    "- droppar os valores;\n",
    "- remapear as categorias;\n",
    "- inferir os valores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b70b2e",
   "metadata": {},
   "source": [
    "Boa prática: sempre que tivermos categorias, armazenar log (em dicionário ou dataframe) das categorias admitidas;\n",
    "\n",
    "Daí, podemos fazer um (anti) joinning para retornar os dados do dataframe (esquerda) que não estão no log de categorias (direita). Método Difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4345d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printa valores que não estão no log de categorias permitidas\n",
    "inconsistent_categories = set(df['cat']).difference(df_log(['cat']))\n",
    "print(inconsistent_categories)\n",
    "\n",
    "# registros inconsistentes\n",
    "inconsistent_rows = df['cat'].isin(inconsistent_categories)\n",
    "inconsistent_data = df[inconsistent_rows]\n",
    "\n",
    "# dropando\n",
    "consistent_data = df[~inconsistent_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53fe7f",
   "metadata": {},
   "source": [
    "Inconsistência de valor:\n",
    "Capitalização: quando se espera o valor 'single' e tem o valor 'Single' ou 'SINGLE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eae90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contando os valores categóricos:\n",
    "df['cat'].value_counts() # só funciona em pandas series\n",
    "df_cat.groupby('cat').count() # para dataframe podemos agrupar pela coluna\n",
    "\n",
    "# tansformando a capitalização:\n",
    "df['cat'] = df['cat'].str.upper()\n",
    "df['cat'] = df['cat'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edad134",
   "metadata": {},
   "source": [
    "Espaços desnecessários (trailing spaces): 'single ' ou ' single'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf54f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat'] = df['cat'].str.strip() # default remove espaços à direita e esquerda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0796d5",
   "metadata": {},
   "source": [
    "##### Colapsando dados\n",
    "Agrupando range de valores por categoria\n",
    "\n",
    "exemplo: grupo de renda a partir do dado de renda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# método qcut:\n",
    "ranges = [0,200,500,np.inf]\n",
    "group_names = ['0-200', '200-500','500+']\n",
    "\n",
    "df['grupos'] = pd.cut(df['renda'],bins = ranges, labels = group_names) \n",
    "\n",
    "print(df[['grupos','renda']]) \n",
    "\n",
    "\n",
    "# existe o método qcut, voce nao define o range então ele categoriza na ordem\n",
    "df['grupos'] = pd.cut(df['renda'],q = 3, labels = group_names) # q é o numero de grupos; classifica na ordem dividindo igualmente pra cada grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d111dd8",
   "metadata": {},
   "source": [
    "Redizir o número de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando dicionário de mapeamento e método replace:\n",
    "map_dict = {} # chave é o antigo valor, definição é o novo valor\n",
    "\n",
    "df['cat'] = df['cat'].replace(map_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0965251",
   "metadata": {},
   "source": [
    "Limpando textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add51768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituição de caracteres\n",
    "df['cat'] = df['cat'].str.replace(\"+\", \"00\") # substitui mais por zero zero\n",
    "df['cat'] = df['cat'].str.replace(\"-\", \"\") # remove traços\n",
    "\n",
    "# checagem\n",
    "assert df['cat'].str.contains(\"+|-\").any() == False # '|' é igual a OU\n",
    "\n",
    "# eliminando strings com caracteres além do limite:\n",
    "digits = df['cat'].str.len() # extraindo a quantidade de caracteres\n",
    "df.loc[digits<10, 'cat'] = np.nan\n",
    "\n",
    "# checagem\n",
    "sanity_check = df['cat'].str.len()\n",
    "assert sanity_check.min() >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f67e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para limpezas mais complexas usamos regex\n",
    "df['numbers'] = df['numbers'].str.replace(r'\\D+',\"\") # removendo qualquer digito naõ numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf33f8",
   "metadata": {},
   "source": [
    "# Uniformidade\n",
    "\n",
    "Problemas: grandezas com unidades diferentes, datas com formatos diferentes, casas decimais existentes ou não.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f4d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unidades diferentes: \n",
    "# plote o scatter dos valores pra perceber o problema (escalas diferentes podem dar aglomerações diferentes)\n",
    "# pesquise a fórmula e faça a conversão de unidade dos dados filtrados a partir de um limite (linha que divide os clusters)\n",
    "\n",
    "\n",
    "# datas diferentes: \n",
    "# converta para datetime (pode causar erro caso haja datas impossíveis)\n",
    "# então faça assim:\n",
    "df['date'] = pd.to_datetime(df['date'],\n",
    "                            infer_datetime_format=True, # tenta inferir formato da data\n",
    "                            errors='coerce') # retorna na quando não consegue\n",
    "\n",
    "# convertendo data para um formato específico:\n",
    "df['date'] = df['date'].dt.strftime(\"%d-%m-%Y\") \n",
    "\n",
    "# ainda assim, podemos ter dados impossíveis de inferir; ex.: 2019-03-08 é 8 de março ou 3 de agosto?\n",
    "    # pode-se dropar o registro, tentar inferir de outros registros, chutar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493fac0",
   "metadata": {},
   "source": [
    "## Validação de campo crusado / cross field validation\n",
    "\n",
    "Utilizar mais de um campo para validar o formato dos números.\n",
    "\n",
    "Ex.: utilizar a soma dos acidentes graves e não graves para comparar com o total de acidentes em cada linha.\n",
    "Ex.: hoje - data de aniversário == idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88bc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_classes = flights[['economy_class', 'business_class', 'first_class']].sum(axis = 1)\n",
    "    # sum horizontally\n",
    "passenger_equ = sum_classes == flights['total_passengers']\n",
    "    # compare to total of the register\n",
    "# Find and filter out rows with inconsistent passenger totals\n",
    "inconsistent_pass = flights[~passenger_equ]\n",
    "consistent_pass = flights[passenger_equ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c09361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "# Convert to datetime and get today's date\n",
    "users['Birthday'] = pd.to_datetime(users['Birthday'])\n",
    "today = dt.date.today()\n",
    "# For each row in the Birthday column, calculate year difference\n",
    "age_manual = today.year - users['Birthday'].dt.year\n",
    "# Find instances where ages match\n",
    "age_equ = age_manual == users['Age']\n",
    "# Find and filter out rows with inconsistent age\n",
    "inconsistent_age = users[~age_equ]\n",
    "consistent_age = users[age_equ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508af276",
   "metadata": {},
   "source": [
    "Providências:\n",
    "- dropar\n",
    "- atribuir Na e tratar depois\n",
    "- aplicar regras de conhecimento de  domínio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd83bb",
   "metadata": {},
   "source": [
    "## Dados Faltantes\n",
    "\n",
    "Pode ser representados por NaN (not a number), Na, 0, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc911468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna() # retorna True e False pra cada valor de célula.\n",
    "df.isna().sum() # retorna o total de NaNs por coluna\n",
    "\n",
    "# retornar dataframe filtrado por dados faltantes e não faltantes:\n",
    "df[df['coluna'].isna()]  # registros com dados faltantes nessa coluna\n",
    "df[~df['coluna'].isna()] # registros completos nessa coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a483a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "# pacote útil para visualizar e entender dados faltantes\n",
    "\n",
    "msno.matrix(df) # mostra a distribuição dos valores faltantes pra cada coluna (linha branca)\n",
    "    # combinados com sort_values, podemos observar se há lógica nessa falta de dados:\n",
    "        # ex.: ordenar o df por uma temperatura, \n",
    "        # podemos observar que para baixas temperaturas o sensor não consegue ler o nível de oxigênio no ar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240a751",
   "metadata": {},
   "source": [
    "#### Tipos de dados faltantes:\n",
    "\n",
    "- MCAR (missing completely at random): sem relação sistemática entre dados faltantes e outros valores\n",
    "    - ex.: erros de entrada de dados\n",
    "- MAR (missing at random): com relação sistemática entre dados faltantes e outros valores observados\n",
    "    - ex.: erros de leitura de ozônio a altas temperaturas\n",
    "- MNAR (missing not at random): relação sistemática entre dados faltantes e variáveis não observadas\n",
    "    - ex.: erros de letura de temperatura a altas temperaturas\n",
    "    - Não há como classificar nesse tipo apenas observando os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c6e73",
   "metadata": {},
   "source": [
    "#### LIdando com dados faltantes:\n",
    "\n",
    "- dropando o registro\n",
    "- substituir por medida estatística (média, mediana, moda)\n",
    "- Abordagens mais complexas:\n",
    "    - imputando uma abordagem algorítmica\n",
    "    - imputando com modelos de machine learning\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando:\n",
    "df_dropped = df.dropna(subset=['coluna'])\n",
    "\n",
    "# substituindo:\n",
    "coluna_mean = df['coluna'].mean()\n",
    "df_replaced = df.fillna({'coluna': coluna_mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f67e0b",
   "metadata": {},
   "source": [
    "\n",
    "## Comparando strings\n",
    "minimun edit distance / distância mínima de edição:\n",
    "- maneira sistemática de identificar semelhança entre strings.\n",
    "- Def.: mínimo número de passos necessários para transformar uma string em outra com as operações:\n",
    "    - Inserção de caracteres, remoção, substituição e transposição.\n",
    "\n",
    "Exemplo: INTENTION -> EXECUTION\n",
    "\n",
    "INTENTION -> *NTENTION -> *NTECNTION -> *ETECNTION -> *EXECNTION -> *EXECUTION\n",
    "<p>Tira I, inclui C, substitui N por E, T por X, N por U = 5 passos</p>\n",
    "\n",
    "Para encontrar esses mínimos existem vários algoritmos que usam um ou mais dessas operações.\n",
    "<p>Algorithm: Operations\n",
    "<p>Damerau-Levenshtein: insertion,substitution,deletion,transposition\n",
    "<p>Levenshtein: insertion,substitution,deletion\n",
    "<p>Hamming: substitution only\n",
    "<p>Jaro distance: transposition only\n",
    "<p>......Possible packages:nltk,fuzzywuzzy,textdistance..\n",
    "\n",
    "\n",
    "#### Comparando strings: similaridade\n",
    "É um score de similaridade. Sendo 0: completamente diferentes e 100: identicos.\n",
    "- usaremos o algoritmo Levenshtein (inserção, substituição, deleção) com o pacote fuzzywuzzy. Ele retorna um score de similaridade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c183369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\lmadr\\anaconda3\\envs\\testenv\\lib\\site-packages (0.18.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf785a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importa pacote\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "fuzz.WRatio('Reeding', 'Reading') # Reeding é erro de digitação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce549fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio('Los Angeles Lakers', 'Lakers') # Similaridade com palavra chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6328a8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio('Houston Rockets vs Los Angeles Lakers', 'Lakers vs Rockets') # ordenamento diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f25444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rockets vs Lakers', 86, 0),\n",
       " ('Lakers vs Rockets', 86, 1),\n",
       " ('Houson vs Los Angeles', 86, 2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPARAR UMA STRING COM UMA ARRAY DE STRINGS. \n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Define string and array of possible matches\n",
    "string = \"Houston Rockets vs Los Angeles Lakers\"\n",
    "choices = pd.Series(['Rockets vs Lakers', 'Lakers vs Rockets', 'Houson vs Los Angeles', 'Heat vs Bulls'])\n",
    "\n",
    "process.extract(string, choices, limit = 3)\n",
    "# RETORNA <limit> TUPLAS DE ESTRUTURA (string, minimun edit distance, ordem de maior minimun edit distance para a menor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colapsando em categorias strings similares\n",
    "print(df['categoria'].unique()) # observe os valores únicos\n",
    "\n",
    "# crie um dataframe com as strings que serão as categorias\n",
    "categories = pd.DataFrame({'state': {0: 'California', 1: 'New York'}})\n",
    "\n",
    "for state in categories['state']:\n",
    "    # encontrar possíveis matches:\n",
    "    matches = process.extract(state, df['categoria'], limit = df.shape[0]) # df.shape[0] é o número de linhas/categorias\n",
    "\n",
    "    for potential_match in matches:\n",
    "        # se a similaridade for alta (segundo termo da tupla >= 80)\n",
    "        if potential_match[1] >=80:\n",
    "            # substitui pela categoria:\n",
    "            df.loc[df['categoria'] == potential_match[0], 'categoria'] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = df['categoria'].unique()\n",
    "print(process.extract('exemplo', unique_types, limit = len(unique_types)))\n",
    "# observando este print, podemos estabelecer o valor limite do score para essa categoria.\n",
    "# repetir o processo para os demais valores alvo da categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de775b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tudo junto:\n",
    "# Iterate through categories\n",
    "for cuisine in categories:  # categorias alvo\n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      restaurants.loc[restaurants['cuisine_type'] == match[0]] = cuisine\n",
    "      \n",
    "# Inspect the final result\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf442e2",
   "metadata": {},
   "source": [
    "## Record linkage / ligação de registros\n",
    "<p>Def.: ato de vincular dados de diferentes fontes em relação à mesma entidade. Seguindo as etapas:</p>\n",
    "\n",
    "- Obter dados de diferentes fontes\n",
    "- gerar pares (correspondencia entre as bases de dados)\n",
    "- comparar os pares (gerar os scores)\n",
    "- parear scores (selecionar limites)\n",
    "- linkar os dados (merge, observando as regras de negócio para duplicatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e677",
   "metadata": {},
   "source": [
    "- Condição ideal: comparar cada registro da base A com a base B (len(A)*len(B) registros, escala muito mal)\n",
    "- Blocking: usar uma das informações de colunas para eliminar vários pares desnecessários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbe1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pacote\n",
    "import recordlinkage\n",
    "\n",
    "# criando o objeto: de indexação/ indexer\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# blocking (block method): gernando pares bloqueados na coluna 'coluna1'\n",
    "indexer.block('coluna1') # qual a melhor coluna pra cá?\n",
    "# gerando os pares:\n",
    "pairs = indexer.index(database_A, database_B) \n",
    "    # o objeto resultante é um pandas dataframe com multi-index (índice em duas camadas)\n",
    "    # cada camada de índice representa um índice de registro (??????)\n",
    "\n",
    "# cria o objeto de comparação\n",
    "compare_cl = recordlinkage.Compare()\n",
    "\n",
    "# encontrar pares exatos para coluna1 e coluna2\n",
    "compare_cl.exact('coluna1', 'coluna1', label='coluna1')\n",
    "compare_cl.exact('coluna2', 'coluna2', label='coluna2')\n",
    "\n",
    "# encontrar pares similares:\n",
    "compare_cl.string('coluna3', 'coluna3', threshold=0.85, label='coluna3') #  threshold=0.85 é o limite inferior do score\n",
    "compare_cl.string('coluna4', 'coluna4', threshold=0.85, label='coluna4')\n",
    "\n",
    "# encontrando os matches:\n",
    "potential_matches = compare_cl.compute(pairs, database_A, database_B)\n",
    "    # o output é um pandas dataframe multi-index, cujo primeiro índice é o índice de linha do primeiro dataframe (database_A)\n",
    "    #  o segundo índice é a lista de todos os índices de linha do segundo (database_B) para cada registro do primeiro.\n",
    "    # as colunas são os valores comparados (coluna1 a coluna4, chamados nos métodos exact() e string())\n",
    "    # os valores de célula (0 ou 1) indicam match de forma booleana.\n",
    "\n",
    "# para encontrar potenciais matches: filtrar linhas que somadas estão acima de certo limite (hiperparâmetro ou parâmetro?) (ex.: 2)\n",
    "n = 4 # procura matches em todas as colunas (duplicata)\n",
    "n = 3 # match em 3 de 4 colunas já é sulficiente para declarar duplicata\n",
    "matches = potential_matches[potential_matches.sum(axis=1) >= n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # matches.index -> retorna o multi index em array \n",
    "duplicated_rows = matches.index.get_level_values(1) # qual camada do índice extrair = 1 (segunda camada); pode-se usar o nome da camada tbm\n",
    "\n",
    "# encontrando duplicatas no dataframe 'database_B':\n",
    "database_B_duplicates = database_B[database_B.index.isin(duplicated_rows)] # filtra por indice\n",
    "# encontrando NÃO duplicatas no dataframe 'database_B':\n",
    "non_dup_B = database_B[~database_B.index.isin(duplicated_rows)] # filtra por indice\n",
    "\n",
    "full_database = database_A.append(non_dup_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('testenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2353c9791115e7195597972a25a0e1aef2de38aef3a4d8d253c7755a1bad3fb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
